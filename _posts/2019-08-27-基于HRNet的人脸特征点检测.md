---
layout: post
title: 基于HRNet的人脸特征点检测
categories:
  - 人工智能
description: 基于HRNet的人脸特征点检测
keywords: 'HRNet, 人脸识别, 人脸特征点检测'
comments: true
---

# 基于HRNet的人脸特征点检测
## 摘要
&emsp;&emsp;在本篇文章中我们主要研究**人脸特征点检测**，使用的网络结构为中科大与微软亚洲研究院，发布的HRNet。HRNet着重于输出可靠的高分辨率表征（reliable highresolution representation）。目前现有的大多数方法都是从高分辨率到低分辨率网络（high-to-low resolution network）产生的低分辨率表征中恢复高分辨率表征。相反，HRNet能在整个过程中都保持**高分辨率的表征**。
&emsp;&emsp;HRNet从高分辨率子网络（high-resolution subnetwork）作为第一阶段开始，逐步增加高分辨率到低分辨率的子网，形成更多的阶段，**并将多分辨率的子网并行连接**。之后通过多次多尺度融合，使得每一个高分辨率到低分辨率的表征都从其他并行表示中反复接收信息，从而得到丰富的高分辨率表征。因此预测的人脸特征可能更准确，在空间上也更精确。论文地址：[High-Resolution Representations for Labeling Pixels and Regions](https://arxiv.org/pdf/1904.04514.pdf)

## 简介
&emsp;&emsp;纵观深度学习的发展表明，深度卷积神经网络已经取得非常优越的性能。大多数现有的方法，通过一个网络（通常由高分辨率到低分辨率的子网串联而成）传递输入，然后提高分辨率。例如，**Hourglass**通过**对称的低到高分辨率**(symmetric low-to-high process)过程恢复高分辨率。**SimpleBaseline**采用少量的转置卷积层(transposed convolution layers)来生成高分辨率的表示。此外，dilated convolutions还被用于放大高分辨率到低分辨率网络(high-to-low resolution network)的后几层(如**VGGNet**或**ResNet**)。
&emsp;&emsp;**HRNet**(High-Resolution Representaions)高分辨率网络，它能够在整个过程中维护高分辨率的表示。从高分辨率子网作为第一阶段开始，**逐步增加高分辨率到低分辨率的子网**(gradually add high-to-low resolution subnetworks)，形成更多的阶段，**并将多分辨率子网并行连接**。在整个过程中，通过在并行的多分辨率子网络上反复交换信息来进行多尺度的重复融合。通过网络输出的高分辨率表示来估计关键点。生成的网络如图所示。
![HRNet00](/images/posts/AI/hrnet00.jpg)
与现有的网络相比，HRNet有以下两个好处：
* HRNet是并行连接高分辨率到低分辨率的子网，而不是像大多数现有解决方案那样串行连接。因此，HRNet能够保持高分辨率，而不是通过一个低到高的过程恢复分辨率，因此预测的结果可能在空间上更精确。
* 大多数现有的融合方案都将低层和高层的表示集合起来。相反，HRNet使用重复的多尺度融合，利用相同深度和相似级别的低分辨率表示来提高高分辨率表示。因此，其预测的结果可能更准确。

## 1. 网络结构解析
&emsp;&emsp;目前，深度卷积神经网络提供了主流的解决方案。主要有两种方法：**回归关键点位置**regressing the position of keypoints和**估算关键点热图**estimating keypoint heatmaps，然后选择**热值最高**的位置作为关键点。
#### 1.1 High-to-low and low-to-high
&emsp;&emsp;high-to-low 的目标是生成低分辨率和高分辨率的表征，low-to-high 的目标是生成高分辨率的表征。这两个过程可能会重复多次，以提高性能。增加多尺度信息之间的融合是非常有效的，例如原图像和模糊图像进行联合双边滤波可以得到介于两者之间的模糊程度的图像，而RGF滤波就是重复将联合双边滤波的结果作为那张模糊的引导图，这样得到的结果会越来越趋近于原图。同理，不同分辨率的图像采样到相同的尺度反复的融合，加之网络的学习能力，会使得多次融合后的结果更加趋近于正确的表示。

**现有的网络设计模式有：**
* 对称结构，先下采样，再上采样，同时使用跳层连接恢复下采样丢失的信息；
* 级联多字金字塔；
* 先下采样，转置卷积上采样，不使用跳层连接进行数据融合；
* 扩张卷积，减少下采样次数，不使用跳层连接进行数据融合；

如下图所示：
![HRNet01](/images/posts/AI/hrnet01.png)
#### 1.2 多分辨率子网络
**并行高分辨率子网**
&emsp;&emsp;以高分辨率子网为第一阶段，逐步增加高分辨率到低分辨率的子网，形成新的阶段，并将多分辨率子网并行连接。因此，后一阶段并行子网的分辨率由前一阶段的分辨率和下一阶段的分辨率组成。一个包含4个并行子网的网络结构示例如下：
![HRNet02](/images/posts/AI/hrnet02.png)
**重复多尺度融合**
&emsp;&emsp;HRNet中引入了跨并行子网的交换单元，使每个子网重复接收来自其他并行子网的信息。下面是一个展示信息交换方案的示例。将第三阶段划分为若干个交换块，每个块由3个并行卷积单元与1个交换单元跨并行单元进行卷积，得到:
![HRNet02](/images/posts/AI/hrnet03.png)
![HRNet02](/images/posts/AI/hrnet04.png)

&emsp;&emsp;输入为s响应映射：![HRNet02](/images/posts/AI/hrnet05.png)。输出为s响应图：![HRNet02](/images/posts/AI/hrnet06.png)，其分辨率和宽度与输入相同。每个输出都是输入映射的集合![HRNet02](/images/posts/AI/hrnet07.png)。各阶段的交换单元有额外的输出图![HRNet02](/images/posts/AI/hrnet08.png)。
&emsp;&emsp;函数![HRNet02](/images/posts/AI/hrnet09.png)从分辨率i到k对![HRNet02](/images/posts/AI/hrnet10.png)上采样或下采样组成。我们采用步长为3×3的卷积做下采样。例如，向一个步长为3×3卷积做步长为2x2的下采样。两个连续的步长为3×3的卷积使用步长为2的4被上采样。对于上采样，我们采用最简单的最近邻抽样，从1×1卷积校准通道的数量。如果i = k，则![HRNet02](/images/posts/AI/hrnet09.png)只是一个识别连接：![HRNet02](/images/posts/AI/hrnet11.png)。

## 2. 代码解析
#### 2.1 ResNet模块
&emsp;&emsp;**ResNet**（Residual Neural Network）由**微软研究院**的Kaiming He等四名华人提出，通过使用**ResNet Unit**成功训练出了152层的神经网络，并在**ILSVRC2015**比赛中取得冠军，在top5上的错误率为**3.57%**，同时参数量比**VGGNet**低，效果非常突出。**ResNet**的结构可以极快的加速神经网络的训练，模型的准确率也有比较大的提升。同时ResNet的推广性非常好，甚至可以直接用到**InceptionNet**网络中。
&emsp;&emsp;**ResNet**的主要思想是在网络中增加了直连通道，即**Highway Network**的思想。此前的网络结构是性能输入做一个**非线性变换**，而**Highway Network**则允许保留之前网络层的一定比例的输出。**ResNet**的思想和**Highway Network**的思想也非常类似，允许原始输入信息直接传到后面的层中。如下的左图对应于**resnet-18/34**使用的基本块，右图是50/101/152所使用的，由于他们都比较深，所以右图相比于左图使用了**1x1卷积来降维**。
![HRNet02](/images/posts/AI/hrnet12.png)
> 关于ResNet此处不再赘述

**[(a) conv3x3]()**：将原有的pytorch函数固定卷积和尺寸为3重新封装了一次
```
def conv3x3(in_planes, out_planes, stride=1):
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)
```
**[(b) BasicBlock]()**：搭建上图左边的模块。
* 每个卷积块后面连接BN层进行归一化；
* 残差连接前的3x3卷积之后只接入BN，不使用ReLU，避免加和之后的特征皆为正，保持特征的多样；
* 跳层连接：两种情况，当模块输入和残差支路（3x3->3x3）的通道数一致时，直接相加；当两者通道不一致时（一般发生在分辨率降低之后，同分辨率一般通道数一致），需要对模块输入特征使用1x1卷积进行升/降维（步长为2，上面说了分辨率会降低），之后同样接BN，不用ReLU。


